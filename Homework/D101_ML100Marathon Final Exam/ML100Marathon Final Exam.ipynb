{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = \"/content/drive/MyDrive/image_data/train/\"\n",
    "test_path = \"/content/drive/MyDrive/image_data/test/\"\n",
    "print(os.listdir(train_path))\n",
    "\n",
    "# 花朵名稱對應的類別碼\n",
    "flower_mapping = {\"daisy\":0, \"dandelion\":1, \"rose\":2, \"sunflower\":3, \"tulip\":4}\n",
    "flowers = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
    "# 參考資料: ImageDataGenerator: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "# 參考資料: 【深度學習】ImageDataGenerator的使用: https://www.796t.com/content/1546542668.html\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=10, #隨機旋轉角度的上限 (角度值 : 0 ~ 180)\n",
    "                  width_shift_range=0.2, # 左右隨機平移上限\n",
    "                  height_shift_range=0.2, # 上下隨機平移上限\n",
    "                  shear_range=0.2, # 逆時針的剪切變形角度\n",
    "                  zoom_range=0.2, # 影像倍率放大縮小的上限\n",
    "                  horizontal_flip=True, # 是否左右翻轉\n",
    "                  fill_mode=\"nearest\", # 填補周圍空缺方法\n",
    "                  validation_split=0.2) # 測試集採樣比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (240, 320)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path, # 目標目錄\n",
    "                           target_size=IMAGE_SIZE, # 所有影象調整為IMAGE_SIZE\n",
    "                           classes=flowers, \n",
    "                           batch_size=BATCH_SIZE, \n",
    "                           subset=\"training\") # 設為訓練集\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(train_path, \n",
    "                           target_size=IMAGE_SIZE, \n",
    "                           classes=flowers, \n",
    "                           batch_size=BATCH_SIZE, \n",
    "                           subset=\"validation\") # 設為驗證集  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint \n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 以 ResNet50 為基礎來建立模型(遷移學習)\n",
    "# 參考資料: ResNet: https://zhuanlan.zhihu.com/p/31502877\n",
    "resnet = ResNet50(input_shape=(240, 320, 3), weights=\"imagenet\", pooling='avg', include_top=False)\n",
    "# 增加 Dense Layer , 設定此模型5種分類的output , 並以 softmax 產生各類別的機率值\n",
    "output = keras.layers.Dense(5, activation=\"softmax\")(resnet.output)\n",
    "model = Model(inputs=[resnet.input], outputs=[output])\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "# 使用 Adam optimizer, 使用固定的 learning rate \n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "       optimizer=Adam(lr=1e-5),\n",
    "       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_1 = EarlyStopping(monitor=\"val_accuracy\", patience=20)\n",
    "model_checkpoint_1 = ModelCheckpoint(\"best_model_1.h5\", monitor=\"val_accuracy\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "# 參考資料: fit_generator: https://blog.csdn.net/dou3516/article/details/118757164\n",
    "model.fit_generator(train_generator, \n",
    "          steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          validation_data=valid_generator, \n",
    "          validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "          use_multiprocessing=True,\n",
    "          workers=8,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stopping_1, model_checkpoint_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results\n",
    "results = {}\n",
    "results[\"Fixed LR\"] = {'train-loss': model.history.history[\"loss\"],\n",
    "             'valid-loss': model.history.history[\"val_loss\"],\n",
    "             'train-acc': model.history.history[\"accuracy\"],\n",
    "             'valid-acc': model.history.history[\"val_accuracy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "resnet_2 = ResNet50(input_shape=(240, 320, 3), weights=\"imagenet\", pooling='avg', include_top=False)\n",
    "# 增加 Dense Layer , 設定此模型5種分類的output , 並以 softmax 產生各類別的機率值\n",
    "output_2 = keras.layers.Dense(5, activation=\"softmax\")(resnet_2.output)\n",
    "model_2 = Model(inputs=[resnet_2.input], outputs=[output_2])\n",
    "    \n",
    "# 使用 Adam optimizer, 使用較低的 learning rate \n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "        optimizer=Adam(lr=1e-5),\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, min_lr=1e-12, monitor='val_accuracy', patience=5, verbose=1)\n",
    "early_stopping_2 = EarlyStopping(monitor=\"val_accuracy\", patience=20)\n",
    "model_checkpoint_2 = ModelCheckpoint(\"best_model_2.h5\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "\n",
    "model_2.fit_generator(train_generator, \n",
    "          steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "          epochs=100,\n",
    "          validation_data=valid_generator, \n",
    "          validation_steps=valid_generator.samples // BATCH_SIZE,\n",
    "          use_multiprocessing=True,\n",
    "          workers=8,\n",
    "          verbose=1,\n",
    "          callbacks=[reduce_lr, early_stopping_2, model_checkpoint_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Reduced LR\"] = {'train-loss': model_2.history.history[\"loss\"],\n",
    "              'valid-loss': model_2.history.history[\"val_loss\"],\n",
    "              'train-acc': model_2.history.history[\"accuracy\"],\n",
    "              'valid-acc': model_2.history.history[\"val_accuracy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"b\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # 進度條顯示套件 \n",
    "\n",
    "best_model = load_model(\"/content/best_model_2.h5\")\n",
    "\n",
    "# 設定最後的輸出資料\n",
    "X_test = list()\n",
    "id_test = []\n",
    "\n",
    "# 使用 Keras 內建的載入寫法 \n",
    "def load_image(img_path):\n",
    "  img = load_img(img_path, target_size=(240, 320))\n",
    "  img = img_to_array(img)\n",
    "  img = np.expand_dims(img, axis=0)\n",
    "  return img \n",
    "def make_test_data():\n",
    "    global X_test\n",
    "    dir_path = test_path\n",
    "    for img in tqdm(os.listdir(dir_path)):\n",
    "        id_test.append(img[:-4])\n",
    "        path = os.path.join(dir_path, img)\n",
    "        img = load_image(path)\n",
    "        img = np.squeeze(img, axis=0)\n",
    "        X_test.append(np.array(img))\n",
    "make_test_data()        \n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# 輸出預測檔\n",
    "pred = best_model.predict(X_test)\n",
    "pred_digits = np.argmax(pred, axis=1)\n",
    "sub = pd.DataFrame({\"id\": id_test, \"flower_class\": pred_digits})\n",
    "sub.to_csv(\"flower_CNN_ver03.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
